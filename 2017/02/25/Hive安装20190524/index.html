<!DOCTYPE HTML>
<html lang="zh-CN">
<head><meta name="generator" content="Hexo 3.8.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="不圆的石头">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="http://qioinglong.top">
    <!--SEO-->





<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">
    <!--Title-->


<title>Hive安装 | 不圆的石头</title>


    <link rel="alternate" href="/atom.xml" title="不圆的石头" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="/css/font-awesome.min.css?rev=4.5.0">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

    <script>
        (function(){
            var bp = document.createElement('script');
            var curProtocol = window.location.protocol.split(':')[0];
            if (curProtocol === 'https') {
                bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
            }
            else {
                bp.src = 'http://push.zhanzhang.baidu.com/push.js';
            }
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(bp, s);
        })();
    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="main-header" style="background-image:url(http://snippet.shenliyang.com/img/banner.jpg)">
    <div class="main-header-box">
        <a class="header-avatar" href="/" title="不圆的石头">
         <!--   <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block"> -->
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                 <img src="/img/branding.png" alt="Snippet 博客主题" class="img-responsive center-block">
            
    	</div>
    </div>
</header>

    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://qioinglong.top">不圆的石头</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>首页</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/金融业务/"><i class="fa "></i>金融业务</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/数据分析/"><i class="fa "></i>数据分析</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/读书/"><i class="fa "></i>读书</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/技术/"><i class="fa "></i>技术</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>时间轴</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="Hive安装">
            
	            Hive安装
            
        </h1>
        <div class="post-meta">
    
    
    <span class="categories-meta fa-wrap">
        <i class="fa fa-folder-open-o"></i>
        <a href="/categories/技术">
            技术
        </a>
    </span>
    

    
    <span class="fa-wrap">
        <i class="fa fa-tags"></i>
        <span class="tags-meta">
            
                
                    <a href="/tags/Hive" title="Hive">
                        Hive
                    </a>
                
            
        </span>
    </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2017/02/25</span>
        </span>
        
    
</div>

            
            
            <p class="fa fa-exclamation-triangle warning">
                本文于<strong>824</strong>天之前发表。
            </p>
        
    </div>
    
    <div class="post-body post-content">
        <h2 id="1-Hive介绍"><a href="#1-Hive介绍" class="headerlink" title="1.Hive介绍"></a>1.Hive介绍</h2><ul>
<li>在Hadoop生态圈中属于数据仓库的角色。Hive能够管理Hadoop中的数据，同时可以查询Hadoop中的数据。它提供了一系列的工具，可以用来进行数据提取转化加载（ETL），这是一种可以存储、查询和分析存储在Hadoop中的大规模数据的机制。</li>
<li>Hive定义了简单的类SQL查询语言，称为HQL ，它允许熟悉SQL的用户查询数据。同时，这个语言也允许熟悉MapReduce开发者的开发自定义的mapper和reducer来处理内建的mapper和reducer无法完成的复杂的分析工作。</li>
<li>本质上讲，Hive是一个SQL解析引擎。Hive可以把SQL查询转换为MapReduce中的job然后在Hadoop执行。Hive有一套映射工具，可以把SQL转换为MapReduce中的job，可以把SQL中的表、字段转换为HDFS中的文件(夹)以及文件中的列。这套映射工具称之为metastore，一般存放在derby、mysql中。</li>
<li>Hive的表其实就是HDFS的目录，按表名把文件夹分开。如果是分区表，则分区值是子文件夹，可以直接在M/R的Job里使用这些数据。    <a id="more"></a>
</li>
</ul>
<h2 id="2-Hive的体系架构"><a href="#2-Hive的体系架构" class="headerlink" title="2.Hive的体系架构"></a>2.Hive的体系架构</h2><p><img src="/2017/02/25/Hive安装20190524/Hive安装/Hive体系架构.png" alt="image"></p>
<ul>
<li>用户接口主要有三种：CLI，Client 和 WebUI。其中最常用的是CLI，CLI启动的时候，会同时启动一个Hive副本。Client是Hive的客户端，用户连接至Hive Server。在启动 Client模式的时候，需要指出Hive Server所在节点，并且在该节点启动Hive Server。WebUI是通过浏览器访问Hive</li>
<li>Hive将元数据存储在数据库中，如mysql、derby。Hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等</li>
<li>解释器、编译器、优化器完成HQL查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS中，并在随后有MapReduce调用执行</li>
<li>Hive的数据存储在HDFS中，大部分的查询、计算由MapReduce完成（包含<em>的查询，比如select </em> from tbl不会生成MapRedcue任务）</li>
<li>Hive将元数据存储在RDBMS中  </li>
</ul>
<h2 id="3-Hive的连接模式"><a href="#3-Hive的连接模式" class="headerlink" title="3.Hive的连接模式"></a>3.Hive的连接模式</h2><h3 id="单用户模式："><a href="#单用户模式：" class="headerlink" title="单用户模式："></a>单用户模式：</h3><p>连接到一个In-memory 的数据库Derby，一般用于Unit Test<br><img src="/2017/02/25/Hive安装20190524/Hive安装/单用户模式2.png" alt="image"></p>
<h3 id="多用户模式："><a href="#多用户模式：" class="headerlink" title="多用户模式："></a>多用户模式：</h3><p>通过网络连接到一个数据库中，是最经常使用到的模式【生产模式】<br><img src="/2017/02/25/Hive安装20190524/Hive安装/多用户模式2.png" alt="image"></p>
<h3 id="远程服务器模式："><a href="#远程服务器模式：" class="headerlink" title="远程服务器模式："></a>远程服务器模式：</h3><p>用于非Java客户端访问元数据库，在服务器端启动MetaStoreServer，客户端利用Thrift协议通过MetaStoreServer访问元数据库<br><img src="/2017/02/25/Hive安装20190524/Hive安装/远程服务器2.png" alt="image"></p>
<h2 id="4-Hive数据存储"><a href="#4-Hive数据存储" class="headerlink" title="4.Hive数据存储"></a>4.Hive数据存储</h2><p>对于数据存储，Hive没有专门的数据存储格式，也没有为数据建立索引，用户可以非常自由的组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符，Hive就可以解析数据。Hive中所有的数据都存储在HDFS中，存储结构主要包括数据库、文件、表和视图。Hive中包含以下数据模型：Table内部表，External Table外部表，Partition分区，Bucket桶。Hive默认可以直接加载文本文件，还支持sequence file 、RCFile。</p>
<h3 id="Hive数据库："><a href="#Hive数据库：" class="headerlink" title="Hive数据库："></a>Hive数据库：</h3><p>类似传统数据库的DataBase，在第三方数据库里实际是一张表。简单示例命令行 hive &gt; create database databasetest;</p>
<h3 id="内部表："><a href="#内部表：" class="headerlink" title="内部表："></a>内部表：</h3><p>Hive的内部表与数据库中的Table在概念上是类似。每一个Table在Hive中都有一个相应的目录存储数据。例如一个表test，它在HDFS中的路径为/input/test，其中input是在hive-site.xml中由${hive.metastore.warehouse.dir} 指定的数据仓库的目录，所有的Table数据（不包括External Table）都保存在这个目录中。删除表时，元数据与数据都会被删除。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">内部表简单示例：</span><br><span class="line">创建数据文件：test_table.txt</span><br><span class="line">创建表：create table test_table (key string)</span><br><span class="line">加载数据：LOAD DATA LOCAL INPATH ‘filepath’ INTO TABLE test_table</span><br><span class="line">查看数据：select * from test_table;  select count(*) from test_table</span><br><span class="line">删除表：drop table test_table</span><br></pre></td></tr></table></figure></p>
<h3 id="外部表"><a href="#外部表" class="headerlink" title="外部表:"></a>外部表:</h3><p>外部表指向已经在HDFS中存在的数据，可以创建Partition。它和内部表在元数据的组织上是相同的，而实际数据的存储则有较大的差异。内部表的创建过程和数据加载过程这两个过程可以分别独立完成，也可以在同一个语句中完成，在加载数据的过程中，实际数据会被移动到数据仓库目录中；之后对数据对访问将会直接在数据仓库目录中完成。删除表时，表中的数据和元数据将会被同时删除。而外部表只有一个过程，加载数据和创建表同时完成（CREATE EXTERNAL TABLE ……LOCATION），实际数据是存储在LOCATION后面指定的 HDFS 路径中，并不会移动到数据仓库目录中。当删除一个External Table时，仅删除该链接。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">外部表简单示例：</span><br><span class="line">创建数据文件：external_table.txt</span><br><span class="line">创建表：create external table external_table (key string)</span><br><span class="line">加载数据：LOAD DATA INPATH ‘filepath’ INTO TABLE external_table</span><br><span class="line">查看数据：select * from external_table;  •select count(*) from external_table</span><br><span class="line">删除表：drop table external_table</span><br></pre></td></tr></table></figure></p>
<h3 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h3><p>Partition对应于数据库中的Partition列的密集索引，但是Hive中Partition的组织方式和数据库中的很不相同。在Hive中，表中的一个Partition对应于表下的一个目录，所有的Partition的数据都存储在对应的目录中。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">分区表简单示例：</span><br><span class="line">创建数据文件：test_partition_table.txt</span><br><span class="line">创建表：create table test_partition_table (key string) partitioned by (dt string)</span><br><span class="line">加载数据：LOAD DATA INPATH ‘filepath’ INTO TABLE test_partition_table partition (dt=‘2006’)</span><br><span class="line">查看数据：select * from test_partition_table;  select count(*) from test_partition_table</span><br><span class="line">删除表：drop table test_partition_table</span><br></pre></td></tr></table></figure></p>
<h3 id="桶"><a href="#桶" class="headerlink" title="桶"></a>桶</h3><p>Buckets是将表的列通过Hash算法进一步分解成不同的文件存储。它对指定列计算hash，根据hash值切分数据，目的是为了并行，每一个Bucket对应一个文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">桶的简单示例：</span><br><span class="line">创建数据文件：test_bucket_table.txt</span><br><span class="line">创建表：create table test_bucket_table (key string) clustered by (key) into 20 buckets</span><br><span class="line">加载数据：LOAD DATA INPATH ‘filepath’ INTO TABLE test_bucket_table</span><br><span class="line">查看数据：select * from test_bucket_table;  set hive.enforce.bucketing = true;</span><br></pre></td></tr></table></figure></p>
<h3 id="Hive的视图"><a href="#Hive的视图" class="headerlink" title="Hive的视图"></a>Hive的视图</h3><p>视图与传统数据库的视图类似。视图是只读的，它基于的基本表，如果改变，数据增加不会影响视图的呈现；如果删除，会出现问题。•如果不指定视图的列，会根据select语句后的生成。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">示例：create view test_view as select * from test</span><br></pre></td></tr></table></figure></p>
<h2 id="5-Hive执行原理"><a href="#5-Hive执行原理" class="headerlink" title="5.Hive执行原理"></a>5.Hive执行原理</h2><p><img src="/2017/02/25/Hive安装20190524/Hive安装/Hive执行原理.png" alt=""><br>Hive构建在Hadoop之上，</p>
<ul>
<li>HQL中对查询语句的解释、优化、生成查询计划是由Hive完成的</li>
<li>所有的数据都是存储在Hadoop中</li>
<li>查询计划被转化为MapReduce任务，在Hadoop中执行（有些查询没有MR任务，如：select * from table）</li>
<li>Hadoop和Hive都是用UTF-8编码的</li>
<li>Hive编译器将一个Hive QL转换操作符。操作符Operator是Hive的最小的处理单元，每个操作符代表HDFS的一个操作或者一道MapReduce作业。Operator都是hive定义的一个处理过程.</li>
</ul>
<h2 id="6-下载解压Hive2-1-1安装包"><a href="#6-下载解压Hive2-1-1安装包" class="headerlink" title="6.下载解压Hive2.1.1安装包"></a>6.下载解压Hive2.1.1安装包</h2><p>下载地址：<br><a href="http://apache.fayea.com/hive/hive-2.1.1/" target="_blank" rel="noopener">http://apache.fayea.com/hive/hive-2.1.1/</a><br>tar -zxvf apache-hive-2.1.1-bin.tar.gz -C /home/yangql/app</p>
<h2 id="7-配置Hive的环境变量"><a href="#7-配置Hive的环境变量" class="headerlink" title="7.配置Hive的环境变量"></a>7.配置Hive的环境变量</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /home/yangql/.bash_profile</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Hive</span><br><span class="line">export HIVE_HOME=/home/yangql/app/hive-2.1.1</span><br><span class="line">export HIVE_CONF_DIR=$HIVE_HOME/conf</span><br><span class="line">export CLASSPATH=$CLASSPATH:$HIVE_HOME/lib</span><br><span class="line">export PATH=$PATH:$HIVE_HOMW/bin</span><br></pre></td></tr></table></figure>
<h2 id="8-单用户配置Hive"><a href="#8-单用户配置Hive" class="headerlink" title="8.单用户配置Hive"></a>8.单用户配置Hive</h2><ul>
<li><p>配置 hive-log4j2.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd $HIVE_HOME/conf  </span><br><span class="line">cp hive-log4j2.properties.template hive-log4j2.properties  </span><br><span class="line">修改  </span><br><span class="line">property.hive.log.dir = /home/yangql/app/hive-2.1.1/logs</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化 schematool -dbType derby -initSchema</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[yangql@hadoop01 logs]$ schematool -dbType derby -initSchema</span><br><span class="line">which: no hbase in (/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/jdk1.8.0_91/bin:/opt/scala-2.12.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/app/hive-2.1.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/bin)</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/yangql/app/hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/yangql/app/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line">Metastore connection URL:	 jdbc:derby:;databaseName=metastore_db;create=true</span><br><span class="line">Metastore Connection Driver :	 org.apache.derby.jdbc.EmbeddedDriver</span><br><span class="line">Metastore connection User:	 APP</span><br><span class="line">Starting metastore schema initialization to 2.1.0</span><br><span class="line">Initialization script hive-schema-2.1.0.derby.sql</span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动Hadoop 集群</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh /home/yangql/app/hadoop-2.7.2/sbin/start-all.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动hiveserver2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup hive --service hiveserver2 &amp;</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行命令hive进入到Hive Shell</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 0.499 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="9-配置MySQL"><a href="#9-配置MySQL" class="headerlink" title="9.配置MySQL"></a>9.配置MySQL</h2><ul>
<li><p>相关安装文档参见《Linux下MySQL安装》</p>

</li>
<li><p>将MySQL的驱动包放置到$HIVE_HOME/lib目录下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp mysql-connector-java-5.1.40-bin.jar /home/yangql/app/hive-2.1.1/lib/</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="10-修改配置文件：hive-site-xml"><a href="#10-修改配置文件：hive-site-xml" class="headerlink" title="10.修改配置文件：hive-site.xml"></a>10.修改配置文件：hive-site.xml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;jdbc:mysql://hadoop01:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.querylog.location&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/yangql/app/hive-2.1.1/querylog&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/home/yangql/app/hive-2.1.1/operlog&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/yangql/app/hive-2.1.1/javaiotmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/yangql/app/hive-2.1.1/javaiotmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<h2 id="11-执行schematool命令进行初始化"><a href="#11-执行schematool命令进行初始化" class="headerlink" title="11.执行schematool命令进行初始化"></a>11.执行schematool命令进行初始化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[yangql@hadoop01 conf]$ schematool -dbType mysql -initSchema</span><br><span class="line">which: no hbase in (/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/jdk1.8.0_91/bin:/opt/scala-2.12.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/app/hive-2.1.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/bin)</span><br><span class="line">Metastore connection URL:	 jdbc:mysql://hadoop01:3306/hive?createDatabaseIfNotExist=true</span><br><span class="line">Metastore Connection Driver :	 com.mysql.jdbc.Driver</span><br><span class="line">Metastore connection User:	 root</span><br><span class="line">Starting metastore schema initialization to 2.1.0</span><br><span class="line">Initialization script hive-schema-2.1.0.mysql.sql</span><br><span class="line">Initialization script completed</span><br><span class="line">schemaTool completed</span><br></pre></td></tr></table></figure>
<h2 id="12-验证"><a href="#12-验证" class="headerlink" title="12.验证"></a>12.验证</h2><ul>
<li><p>执行hive，进入到Hive Shell</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[yangql@hadoop01 conf]$ hive</span><br><span class="line">which: no hbase in (/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/jdk1.8.0_91/bin:/opt/scala-2.12.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/app/hive-2.1.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/bin)</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration in file:/home/yangql/app/hive-2.1.1/conf/hive-log4j2.properties Async: true</span><br><span class="line">Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. tez, spark) or using Hive 1.X releases.</span><br><span class="line">hive&gt; show databases;</span><br><span class="line">OK</span><br><span class="line">default</span><br><span class="line">Time taken: 1.654 seconds, Fetched: 1 row(s)</span><br><span class="line">hive&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看MySQL数据库是否有hive数据库</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[yangql@hadoop01 ~]$ mysql -u root -p</span><br><span class="line">Enter password:</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 44</span><br><span class="line">Server version: 5.1.73 Source distribution</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| hive               |</span><br><span class="line">| mysql              |</span><br><span class="line">| test               |</span><br><span class="line">| yangql             |</span><br><span class="line">| yangql01           |</span><br><span class="line">+--------------------+</span><br><span class="line">6 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="13-远程模式"><a href="#13-远程模式" class="headerlink" title="13.远程模式"></a>13.远程模式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup hive --service metastore&amp;</span><br></pre></td></tr></table></figure>
<h2 id="错误解决"><a href="#错误解决" class="headerlink" title="错误解决"></a>错误解决</h2><ul>
<li>问题1：Hive 和 hadoop jar包 slf4j-log4j12-1.7.10.jar冲突</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">which: no hbase in (/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/jdk1.8.0_91/bin:/opt/scala-2.12.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/home/yangql/app/hive-2.1.1/bin:/home/yangql/bin:/home/yangql/app/hadoop-2.7.2/bin:/home/yangql/app/sqoop-1.4.6/bin:/home/yangql/app/spark-2.1.0-bin-hadoop2.7/bin:/home/yangql/app/zookeeper-3.4.6/bin:/bin)</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/yangql/app/hive-2.1.1/lib/log4j-slf4j-impl-2.4.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding in [jar:file:/home/yangql/app/hadoop-2.7.2/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</span><br><span class="line">SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]</span><br><span class="line"></span><br><span class="line">Logging initialized using configuration in file:/home/yangql/app/hive-2.1.1/conf/hive-log4j2.properties Async: true</span><br><span class="line">Exception in thread &quot;main&quot; java.lang.RuntimeException: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:591)</span><br><span class="line">	at org.apache.hadoop.hive.ql.session.SessionState.beginStart(SessionState.java:531)</span><br><span class="line">	at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:705)</span><br><span class="line">	at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:641)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:606)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)</span><br><span class="line">	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)</span><br><span class="line">Caused by: org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:226)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.&lt;init&gt;(Hive.java:366)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:310)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:290)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:266)</span><br><span class="line">	at org.apache.hadoop.hive.ql.session.SessionState.start(SessionState.java:558)</span><br><span class="line">	... 9 more</span><br><span class="line">Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient</span><br><span class="line">	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1654)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.&lt;init&gt;(RetryingMetaStoreClient.java:80)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:130)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:101)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3367)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3406)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3386)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3640)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:236)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:221)</span><br><span class="line">	... 14 more</span><br><span class="line">Caused by: java.lang.reflect.InvocationTargetException</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)</span><br><span class="line">	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)</span><br><span class="line">	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)</span><br><span class="line">	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1652)</span><br><span class="line">	... 23 more</span><br><span class="line">Caused by: MetaException(message:Version information not found in metastore. )</span><br><span class="line">	at org.apache.hadoop.hive.metastore.ObjectStore.checkSchema(ObjectStore.java:7753)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.ObjectStore.verifySchema(ObjectStore.java:7731)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:606)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:101)</span><br><span class="line">	at com.sun.proxy.$Proxy20.verifySchema(Unknown Source)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:565)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:626)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:416)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.&lt;init&gt;(RetryingHMSHandler.java:78)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:84)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6490)</span><br><span class="line">	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.&lt;init&gt;(HiveMetaStoreClient.java:238)</span><br><span class="line">	at org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.&lt;init&gt;(SessionHiveMetaStoreClient.java:70)</span><br><span class="line">	... 28 more</span><br></pre></td></tr></table></figure>
<p>解决办法：删除可解决问题：rm -rf slf4j-log4j12-1.7.10.jar</p>
<ul>
<li>MySQL连接被拒绝<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p root</span><br><span class="line">grant all privileges on *.* to root@&apos;hadoop01&apos; identified by &apos;root&apos;;</span><br><span class="line">flush privileges;</span><br><span class="line">exit;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>*.*代表全部数据库的全部表授权，也可以指定数据库授权，如test_db.*<br>all privileges代表全部权限，也可以insert,update,delete,create,drop等；<br>允许root用户在hadoop01（Linux系统的主机名，IP映射）进行远程登陆，并设置root用户的密码为root。<br>flush privileges告诉服务器重新加载授权表。</p>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2017/02/25/Hive权限控制20190524/" class="pre-post btn btn-default" title="Hive权限控制">
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">Hive权限控制</span>
        </a>
    
    
        <a href="/2017/02/24/Spark-学习笔记-120190524/" class="next-post btn btn-default" title="Spark-学习笔记-1">
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Spark-学习笔记-1</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>


    <div id="comments">
        
	
    <div id="vcomments" class="valine"></div>
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="/assets/valine.min.js"></script>

    <script>
        new Valine({
            av: AV,
            el: '#vcomments',
            appId: 'kuH6vv7OvJtqnW8MALiD7bCT-gzGzoHsz',
            appKey: 'vYla34T6SnCwnMeGoMzh8VDn',
            placeholder: '说点什么吧',
            notify: false,
            verify: false,
            avatar: 'null',
            meta: 'nick'.split(','),
            pageSize: '10',
            path: window.location.pathname,
            lang: 'zh-CN'.toLowerCase()
        })
    </script>


    </div>





                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">文章目录</h3>
        
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Hive介绍"><span class="toc-text">1.Hive介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Hive的体系架构"><span class="toc-text">2.Hive的体系架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-Hive的连接模式"><span class="toc-text">3.Hive的连接模式</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#单用户模式："><span class="toc-text">单用户模式：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#多用户模式："><span class="toc-text">多用户模式：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#远程服务器模式："><span class="toc-text">远程服务器模式：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Hive数据存储"><span class="toc-text">4.Hive数据存储</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive数据库："><span class="toc-text">Hive数据库：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#内部表："><span class="toc-text">内部表：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#外部表"><span class="toc-text">外部表:</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#分区"><span class="toc-text">分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#桶"><span class="toc-text">桶</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hive的视图"><span class="toc-text">Hive的视图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Hive执行原理"><span class="toc-text">5.Hive执行原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-下载解压Hive2-1-1安装包"><span class="toc-text">6.下载解压Hive2.1.1安装包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-配置Hive的环境变量"><span class="toc-text">7.配置Hive的环境变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-单用户配置Hive"><span class="toc-text">8.单用户配置Hive</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-配置MySQL"><span class="toc-text">9.配置MySQL</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-修改配置文件：hive-site-xml"><span class="toc-text">10.修改配置文件：hive-site.xml</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-执行schematool命令进行初始化"><span class="toc-text">11.执行schematool命令进行初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-验证"><span class="toc-text">12.验证</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-远程模式"><span class="toc-text">13.远程模式</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#错误解决"><span class="toc-text">错误解决</span></a></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>


  <script src="https://unpkg.com/mermaid@8.0.0/dist/mermaid.min.js"></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({theme: 'forest'});
    }
  </script>

    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy;2016 -  2019 
                <!-- <span><a href='https://coding.net/pages'>Hosted by CODING Pages</a></span> -->
                </span>
            </div>
        </div>
    </div>
</div>







<script src="/js/app.js?rev=@@hash"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>